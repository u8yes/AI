{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52313ed4",
   "metadata": {},
   "source": [
    "# 보팅 앙상블\n",
    "- 단일 모델을 앙상블하여 더 나은 예측을 하는 앙상블 모델을 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c662b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b0d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손글씨 데이터 로드\n",
    "\n",
    "mnist = datasets.load_digits()\n",
    "fearures, labels = mnist.data, mnist.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(fearures, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc77c9",
   "metadata": {},
   "source": [
    "## 단일 모델 정확도 측정\n",
    "- 의사결정트리, knn, svm 모델의 정확도를 측정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70aaf589",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(criterion='gini', max_depth=8, max_features=32, random_state=35)\n",
    "\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "dtree_predicted = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d1936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=299).fit(X_train, y_train) # n_neighbors값은 gridsearchcv로 찾아야 함.\n",
    "knn_predicted = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ccf70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=0.1, gamma=0.003, probability=True, random_state=35).fit(X_train, y_train) # 전처리로 적합한 값을 찾아야 함.\n",
    "svm_predicted = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba5029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[accuracy]\n",
      "d_tree :  0.8277777777777777\n",
      "knn    :  0.8944444444444445\n",
      "svm    :  0.8916666666666667\n"
     ]
    }
   ],
   "source": [
    "print('[accuracy]')\n",
    "print('d_tree : ', accuracy_score(y_test, dtree_predicted))\n",
    "print('knn    : ', accuracy_score(y_test, knn_predicted))\n",
    "print('svm    : ', accuracy_score(y_test, svm_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a7109ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00129293 0.00434548 0.00446459 0.00248053 0.00336731 0.93848315\n",
      "  0.00127073 0.00448341 0.02477231 0.01503956]\n",
      " [0.00189233 0.00631647 0.92958418 0.00345522 0.0030971  0.00828454\n",
      "  0.00186869 0.0048112  0.03092707 0.0097632 ]]\n"
     ]
    }
   ],
   "source": [
    "# 직접 소프트보팅을 구현하실 때는 predict_proba() 함수를 사용하여 테스트 수행 시 측정된 분류값별 확률을 사용하시면 됩니다.\n",
    "\n",
    "svm_proba = svm.predict_proba(X_test)\n",
    "print(svm_proba[0:2]) # 예측값을 2번 봄."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86cce27",
   "metadata": {},
   "source": [
    "## 하드 보팅\n",
    "- 하드 보팅은 일반적인 투표와 같이, 각각의 분류기의 예측값들을 모아, 가장 많은 득표를 받은 예측값으로 최종 결론을 내는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd4e9c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9222222222222223"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('decision_tree', dtree), ('knn', knn), ('svm', svm)], \n",
    "                              weights=[1,1,1], voting='hard').fit(X_train, y_train)\n",
    "# estimators - 평가 모델 # weights - 가중치 \n",
    "hard_voting_predicted = voting_clf.predict(X_test)\n",
    "accuracy_score(y_test, hard_voting_predicted) # 0.9222222222222223 # 여러 모델을 가지고 데이터를 내니까 좋아지기도 하더라."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678c096",
   "metadata": {},
   "source": [
    "## 소프트 보팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f04e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
